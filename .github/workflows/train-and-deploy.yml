# GitHub Actions Workflow for CLV Model Training and Deployment
# Triggers on push to main branch or manual dispatch

name: Train and Deploy CLV Model

on:
  push:
    branches: [main]
    paths:
      - 'src/**'
      - 'requirements.txt'
      - 'config/**'
  workflow_dispatch:
    inputs:
      snapshot_date:
        description: 'Snapshot date for training (YYYY-MM-DD)'
        required: true
        default: '2025-06-04'
      deploy_endpoint:
        description: 'Deploy endpoint after training'
        required: true
        default: 'true'
        type: boolean

env:
  AWS_REGION: us-east-2
  S3_BUCKET: sagemaker-us-east-2-443331476484
  S3_PREFIX: clv-ml
  SAGEMAKER_ROLE: arn:aws:iam::443331476484:role/SageMakerCLVExecutionRole

jobs:
  # ===========================================================================
  # JOB 1: Run unit tests
  # ===========================================================================
  test:
    name: Run Tests
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov
      
      - name: Run tests
        run: |
          python -m pytest tests/ -v --tb=short

  # ===========================================================================
  # JOB 2: Package and upload code to S3
  # ===========================================================================
  package:
    name: Package Code
    runs-on: ubuntu-latest
    needs: test
    outputs:
      source_s3_uri: ${{ steps.upload.outputs.source_uri }}
      timestamp: ${{ steps.upload.outputs.timestamp }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Package source code
        id: upload
        run: |
          TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          echo "timestamp=$TIMESTAMP" >> $GITHUB_OUTPUT
          
          # Create source package
          mkdir -p package
          cp -r src package/
          cp requirements.txt package/
          cp -r config package/
          
          # Create tarball
          cd package
          tar -czvf ../source-$TIMESTAMP.tar.gz .
          cd ..
          
          # Upload to S3
          SOURCE_URI="s3://${{ env.S3_BUCKET }}/${{ env.S3_PREFIX }}/source/source-$TIMESTAMP.tar.gz"
          aws s3 cp source-$TIMESTAMP.tar.gz $SOURCE_URI
          
          echo "source_uri=$SOURCE_URI" >> $GITHUB_OUTPUT
          echo "Source uploaded to: $SOURCE_URI"

  # ===========================================================================
  # JOB 3: Train model on SageMaker
  # ===========================================================================
  train:
    name: Train Model on SageMaker
    runs-on: ubuntu-latest
    needs: package
    outputs:
      model_s3_uri: ${{ steps.train.outputs.model_uri }}
      training_job_name: ${{ steps.train.outputs.job_name }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        run: |
          pip install boto3 sagemaker pyyaml
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Submit SageMaker Training Job
        id: train
        env:
          SNAPSHOT_DATE: ${{ github.event.inputs.snapshot_date || '2025-06-04' }}
        run: |
          python << 'EOF'
          import boto3
          import sagemaker
          from sagemaker.sklearn import SKLearn
          import os
          import time
          
          region = os.environ['AWS_REGION']
          role = os.environ['SAGEMAKER_ROLE']
          bucket = os.environ['S3_BUCKET']
          prefix = os.environ['S3_PREFIX']
          timestamp = '${{ needs.package.outputs.timestamp }}'
          snapshot_date = os.environ['SNAPSHOT_DATE']
          
          session = boto3.Session(region_name=region)
          sm_session = sagemaker.Session(boto_session=session)
          
          # Training data location
          train_data = f"s3://{bucket}/{prefix}/data/"
          output_path = f"s3://{bucket}/{prefix}/models/{timestamp}"
          
          print(f"Training data: {train_data}")
          print(f"Output path: {output_path}")
          print(f"Snapshot date: {snapshot_date}")
          
          # Create estimator
          estimator = SKLearn(
              entry_point='sagemaker_train.py',
              source_dir='src/training',
              framework_version='1.2-1',
              py_version='py3',
              instance_type='ml.m5.large',
              instance_count=1,
              role=role,
              sagemaker_session=sm_session,
              output_path=output_path,
              base_job_name='clv-training',
              hyperparameters={
                  'snapshot-date': snapshot_date,
                  'xdays': 365,
                  'penalizer': 0.0
              },
              dependencies=['requirements.txt'],
              max_run=3600,
              tags=[
                  {'Key': 'Project', 'Value': 'CLV-ML'},
                  {'Key': 'Environment', 'Value': 'production'},
                  {'Key': 'GitCommit', 'Value': '${{ github.sha }}'}
              ]
          )
          
          # Start training
          estimator.fit(
              inputs={'train': train_data},
              wait=True,
              logs='All'
          )
          
          # Get model artifacts location
          model_data = estimator.model_data
          job_name = estimator.latest_training_job.name
          
          print(f"Training complete!")
          print(f"Model artifacts: {model_data}")
          print(f"Training job: {job_name}")
          
          # Write outputs
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"model_uri={model_data}\n")
              f.write(f"job_name={job_name}\n")
          EOF

  # ===========================================================================
  # JOB 4: Deploy endpoint
  # ===========================================================================
  deploy:
    name: Deploy SageMaker Endpoint
    runs-on: ubuntu-latest
    needs: train
    if: ${{ github.event.inputs.deploy_endpoint != 'false' }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        run: |
          pip install boto3 sagemaker pyyaml
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Deploy Endpoint
        env:
          MODEL_URI: ${{ needs.train.outputs.model_s3_uri }}
        run: |
          python << 'EOF'
          import boto3
          import sagemaker
          from sagemaker.sklearn import SKLearnModel
          import os
          
          region = os.environ['AWS_REGION']
          role = os.environ['SAGEMAKER_ROLE']
          model_uri = os.environ['MODEL_URI']
          
          session = boto3.Session(region_name=region)
          sm_session = sagemaker.Session(boto_session=session)
          
          print(f"Deploying model from: {model_uri}")
          
          # Create model
          model = SKLearnModel(
              model_data=model_uri,
              role=role,
              entry_point='sagemaker_entry.py',
              source_dir='src/inference',
              framework_version='1.2-1',
              py_version='py3',
              sagemaker_session=sm_session,
              dependencies=['requirements.txt']
          )
          
          # Deploy endpoint
          endpoint_name = 'clv-prediction-endpoint'
          
          predictor = model.deploy(
              initial_instance_count=1,
              instance_type='ml.m5.large',
              endpoint_name=endpoint_name,
              wait=True
          )
          
          print(f"Endpoint deployed: {endpoint_name}")
          print(f"Endpoint ARN: arn:aws:sagemaker:{region}:443331476484:endpoint/{endpoint_name}")
          EOF
      
      - name: Test Endpoint
        run: |
          python << 'EOF'
          import boto3
          import json
          
          runtime = boto3.client('sagemaker-runtime', region_name='us-east-2')
          
          # Test payload
          test_data = {
              "customers": [
                  {
                      "CustomerID": "TEST-001",
                      "recency": 30,
                      "frequency": 5,
                      "monetary_value": 250.0,
                      "T": 365,
                      "customer_type": "repeater"
                  }
              ]
          }
          
          response = runtime.invoke_endpoint(
              EndpointName='clv-prediction-endpoint',
              ContentType='application/json',
              Body=json.dumps(test_data)
          )
          
          result = json.loads(response['Body'].read().decode())
          print("Test prediction result:")
          print(json.dumps(result, indent=2))
          EOF
